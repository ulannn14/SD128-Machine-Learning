{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEBTerYHgt28"
   },
   "source": [
    "# Introduction to Computer Vision (CIVI1000) Machine Project \n",
    "\n",
    "XC23\n",
    "<br> Albo, Leigh Gwyneth M.\n",
    "<br> Barte, Lian Carlos M.\n",
    "<br> Orcullo, Rlsrain Mackenlhy G.\n",
    "<br> Villamor, Allysa Luise Nelfa D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXsOk6aohAeJ"
   },
   "source": [
    "The first phase of the project involves 4 sections – (1) list of requirements, (2) description of the\n",
    "dataset, (3) exploratory data analysis, and (4) traditional ML model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Machine Project Phase 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iggMTd0bhEnZ"
   },
   "source": [
    "## Section 1. List of requirements\n",
    "Below are the list of Python libraries and modules used in the entirety of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGoYBmbpO1Pk"
   },
   "outputs": [],
   "source": [
    "# Core Data Handling and OS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "\n",
    "# Machine Learning and Metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import resample\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import lru_cache\n",
    "\n",
    "# additional for running in colab\n",
    "import zipfile\n",
    "import sys\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dR7ndMTMRyI-"
   },
   "source": [
    "These libraries form the foundation for both **data preprocessing** and **model development** in this project.\n",
    "\n",
    "- **pandas** and **numpy** - for handling and processing tabular and numerical data.  \n",
    "- **os**, **sys**, and **zipfile** - for working with file paths, directories, and compressed datasets.  \n",
    "- **PIL (Python Imaging Library)** and **cv2 (OpenCV)** - for loading, converting, and resizing images.  \n",
    "- **matplotlib** and **seaborn** - for visualizing images, class distributions, and performance results.  \n",
    "- **tqdm** - for adding progress bars to loops, helping monitor loading or training processes.  \n",
    "- **scikit-learn (sklearn)** - for data splitting, feature scaling, traditional machine learning models (like k-NN and Logistic Regression), PCA for dimensionality reduction, and performance evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvN7ndYfzX6S"
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import compute_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qPxNxWUh6ss"
   },
   "source": [
    "## Section 2. Description of the dataset\n",
    "\n",
    "The clinical skin disease dataset used, named SD-198, is the largest available skin disease database as of 2016, whether clinical or dermoscopic images are mentioned. The dataset is a solution against datasets previously used for skin disease studies that are not publicly available. However, the dataset used for this project is SD-128 which also comprises SD-198. It is assumed that the same processes and discussions were applied in the SD-128 dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihj5k9H-ST7Z"
   },
   "source": [
    "The SD-198 dataset contains 6,584 images in total varying from 198 different skin diseases from different types of eczema, acne, and various cancerous conditions. The SD-128 dataset, which was given for this project, was also chosen containing more than 20 image samples as a subset. It is difficult to distinguish between the skin disease images as some of them may look exactly the same with their color and shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCTKtasnSUKf"
   },
   "source": [
    "As mentioned in the paper, the images are downloaded from DermQuest, which is an online medical resource for dermatologists and healthcare professionals. There are 720 species of skin lesions in total, which include all kinds of conditions that affect the integumentary system; however, a statistical analysis was done and species that rarely appear in real life or have less than 10 samples were removed. To balance the categories of the dataset, some images were removed from subsets that have sufficient data, to keep 60 images at each category at most despite the initial collection of 10,000 clinical skin disease images. Further filtration of the images was then done by removing duplicates and low-quality images. The SD-198 dataset was then finalized with 6,584 images and 198 different skin disease categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLYeiF7YSl-g"
   },
   "source": [
    " However, the information regarding images in SD-128, which is used in this project, will be discussed later in the code. The SD-128 dataset contains the images folder which also contains multiple subfolders where each subfolder represents a class or skin disease. There should be 128 subfolders corresponding to 128 different classes and each subfolder contains at most 60 images. The dataset also contains text files that list the relative file path of the images in the training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVry0-5Z5Z1m"
   },
   "source": [
    "The training and testing datasets are loaded into its own dataframe. The combined dataframe is made by combining the training and testing datasets and is used to visualize the overall dataset of SD-128 for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LA-gibRaPKG8"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('SD-128/train.txt', sep=' ', header=None, names=['Path', 'Label'])\n",
    "test_df = pd.read_csv('SD-128/test.txt', sep=' ', header=None, names=['Path', 'Label'])\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "train_df_cnn = train_df.copy()\n",
    "test_df_cnn = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbziTP9yTafR"
   },
   "source": [
    "To ensure that the data is loaded correctly in the dataframe, information for each dataframe or how it looks in the dataframe is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1762109111481,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "HCyPfFDPSfGh",
    "outputId": "5a2bc114-397c-4591-94c1-83818fd12587"
   },
   "outputs": [],
   "source": [
    "# 1. Initial Data Inspection (Crucial EDA Step)\n",
    "print(\"--- Training Data Info (.info()) ---\")\n",
    "train_df.info()\n",
    "\n",
    "print(\"\\n--- Testing Data Info (.info()) ---\")\n",
    "test_df.info()\n",
    "\n",
    "print(\"\\n--- Overall Data Info (.info()) ---\")\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1762109111535,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "DEuNqPhJULcM",
    "outputId": "3b9c1606-2784-4821-afc6-6918943f5194"
   },
   "outputs": [],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1762109111616,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "Q9H1FsyJUWLJ",
    "outputId": "908e2bc0-d277-4bbc-dfa1-fc5a0f39005c"
   },
   "outputs": [],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1762109111671,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "XVIxBP4k6gSq",
    "outputId": "3d03862d-0632-4373-e000-c6e386eae9b8"
   },
   "outputs": [],
   "source": [
    "combined_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fydFNaRcAgFT"
   },
   "source": [
    "This part of the code prepares a mapping between numeric class labels and their corresponding class names, ensuring that all 128 expected classes are represented even if some are missing in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dQ4J7GU6qu0"
   },
   "outputs": [],
   "source": [
    "label_to_path = combined_df.drop_duplicates(subset='Label').set_index('Label')['Path'].to_dict()\n",
    "label_to_name = {lbl: label_to_path[lbl].split('/')[0] for lbl in label_to_path}\n",
    "\n",
    "expected_min_classes = 128\n",
    "max_label_seen = int(combined_df['Label'].max())\n",
    "total_classes = max(expected_min_classes, max_label_seen + 1)\n",
    "labels = list(range(total_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnkiJiIdA7Po"
   },
   "source": [
    "This loop fills in missing class names to ensure every label from 0 to the 127 has a corresponding entry in label_to_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3Dq_5cl6rWF"
   },
   "outputs": [],
   "source": [
    "for lbl in labels:\n",
    "    if lbl not in label_to_name:\n",
    "        label_to_name[lbl] = f\"Class_{lbl}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohpkeXy_WMMj"
   },
   "source": [
    "This code computes and displays basic dataset statistics for the training, testing, and overall data. The following information shows the characteristics of the SD-128 dataset which the paper wasn't able to specifically discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1762109111753,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "RIJ4J0_TWWZc",
    "outputId": "5aad2949-db63-4117-8ac2-967aa2e654ce"
   },
   "outputs": [],
   "source": [
    "num_train = len(train_df)\n",
    "num_test = len(test_df)\n",
    "num_combined = len(combined_df)\n",
    "num_classes_train = train_df['Label'].nunique()\n",
    "num_classes_test = test_df['Label'].nunique()\n",
    "num_classes = num_classes_train\n",
    "num_classes_combined = combined_df['Label'].nunique()\n",
    "\n",
    "# diff between nunique and .value_count() - nunique return just n classes, while .value counts return n PER classes\n",
    "\n",
    "\n",
    "print(f\"Number of Training Samples: {num_train}\")\n",
    "print(f\"Number of Testing Samples: {num_test}\")\n",
    "print(f\"Number of Overall Samples: {num_combined}\")\n",
    "print(f\"Number of Classes: {num_classes_train}\")\n",
    "print(f\"Number of Classes: {num_classes_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uk3TMAwiZxkY"
   },
   "source": [
    "This code performs class mapping which basically maps the numeric labels into names for exploratory data analysis and representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1762109111770,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "2ddKYAjFZ2zT",
    "outputId": "cb8b35e5-2418-499e-ea71-243b02d2a68e"
   },
   "outputs": [],
   "source": [
    "class_map = combined_df.drop_duplicates(subset='Label').set_index('Label')['Path'].apply(lambda x: x.split('/')[0]).to_dict()\n",
    "class_names = [class_map[i] for i in range(num_classes)]\n",
    "for i in range(num_classes_test):\n",
    "  print(f\"Label {i}: {class_map[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnwJpJyf8eXt"
   },
   "source": [
    "## Section 3. Exploratory data analysis\n",
    "\n",
    "To gain a better understanding of the dataset, identify potentify challenges, and discuss how some factors might affect training outcomes, exploratory data analysis, also known as eda, was done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzTv5New9XPj"
   },
   "source": [
    "The first form of data visualization used is a bar chart for each of the overall, training, and testing datasets. It is important to check for the visualization for each of the datasets to be able to infer whether the sampling between the training and testing is valid or suitable based on how the overall data is distributed.\n",
    "\n",
    "This code presents a bar chart of the overall distribution of images across classes (skin diseases) in the SD-128 dataset. It is essential to check the distribution of samples between classes to detect class imbalance which is said to be common in medical datasets from research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "executionInfo": {
     "elapsed": 1090,
     "status": "ok",
     "timestamp": 1762109112862,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "LqAJwC4z9i71",
    "outputId": "96a2467e-6071-4773-ef8e-ad2822595cbc"
   },
   "outputs": [],
   "source": [
    "class_counts = combined_df['Label'].value_counts().sort_index()\n",
    "\n",
    "labels = sorted(class_counts.index)\n",
    "class_names = [class_map[lbl] for lbl in labels]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(class_names, class_counts)\n",
    "plt.title('Distribution of Images Across Classes in SD-128')\n",
    "plt.xlabel('Disease Name')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BexKC4wKWyj6"
   },
   "source": [
    "Seeing the bar graph for the distribution we can assess that the images are spread randomly among all the classes in SD-128 with a slight disparity in some classes. While most of the classes have a relatively balanced distribution to the classes, there are several diseases that have fewer samples. The noticeable imbalance may affect the model performance since it can lead to biased predictions, but could be indicative of the rarity of the diseases. Other than that, we can still see the diversity of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1762109114082,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "5HGN22BvEbx3",
    "outputId": "e9b42a0f-1551-47fa-9ab6-717363fff703"
   },
   "outputs": [],
   "source": [
    "class_counts_train = train_df['Label'].value_counts().sort_index()\n",
    "\n",
    "labels = sorted(class_counts_train.index)\n",
    "class_names = [class_map[lbl] for lbl in labels]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(class_names, class_counts_train)\n",
    "plt.title('Distribution of Images Across Classes in Training Set')\n",
    "plt.xlabel('Disease Name')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJNgYhTfx08J"
   },
   "source": [
    "For the training set, it contains 128 skin disease classes with up to 30 samples per class, showing both variety and controlled distribution.\n",
    "This combination reflects high diversity, but since image counts range only from 10 to 30, it makes the classification task more challenging for the model.\n",
    "The limited examples per class may also highlight the rarity of certain diseases within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "executionInfo": {
     "elapsed": 1178,
     "status": "ok",
     "timestamp": 1762109115298,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "1cBodm1tEmjm",
    "outputId": "9dd393cf-9a50-4c55-f48c-ff2ff0243cfb"
   },
   "outputs": [],
   "source": [
    "class_counts_test = test_df['Label'].value_counts().sort_index()\n",
    "\n",
    "labels = sorted(class_counts_test.index)\n",
    "class_names = [class_map[lbl] for lbl in labels]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(class_names, class_counts_test)\n",
    "plt.title('Distribution of Images Across Classes in Testing Set')\n",
    "plt.xlabel('Disease Name')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSxZoC_oxAPs"
   },
   "source": [
    "For the testing set, it maintains the same distribution of images as the training data, where most classes contain about 10 to 30 samples and a spread out partitioning of the classes is present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Y2WUacJG0Op"
   },
   "source": [
    "This code simply provides or prints summary statistics of the samples in the overall, training, and testing datasets which can also be seen from the visualization above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1762109115330,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "UCWV3zjW8wtj",
    "outputId": "73e42ea4-7443-4beb-d3e4-bffd041256c0"
   },
   "outputs": [],
   "source": [
    "min_samples = class_counts.min()\n",
    "max_samples = class_counts.max()\n",
    "mean_samples = class_counts.mean()\n",
    "\n",
    "print(\"Overall\")\n",
    "print(\"Min Max Mean\")\n",
    "print(min_samples,\n",
    "      max_samples,\n",
    "      mean_samples)\n",
    "\n",
    "min_samples_train = class_counts_train.min()\n",
    "max_samples_train = class_counts_train.max()\n",
    "mean_samples_train = class_counts_train.mean()\n",
    "\n",
    "print(\"\\nTrain\")\n",
    "print(\"Min Max Mean\")\n",
    "print(min_samples_train,\n",
    "      max_samples_train,\n",
    "      mean_samples_train)\n",
    "\n",
    "min_samples_test = class_counts_test.min()\n",
    "max_samples_test = class_counts_test.max()\n",
    "mean_samples_test = class_counts_test.mean()\n",
    "\n",
    "print(\"\\nTest\")\n",
    "print(\"Min Max Mean\")\n",
    "print(min_samples_test,\n",
    "      max_samples_test,\n",
    "      mean_samples_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwVSPqrHxQHB"
   },
   "source": [
    "Across all 128 skin disease classes, the SD-108 dataset shows a moderate spread in the number of samples per class.\n",
    "\n",
    "- Overall dataset: ranges from 20 to 60 images per class, averaging about 44 samples.\n",
    "\n",
    "- Training and testing sets: both range from 10 to 30 samples per class, averaging around 22 images each.\n",
    "\n",
    "With this, it indicates that the dataset is fairly balanced among the training and testing sets. The limited sample size per class may impose a challenge to the models ability to learn detailed features, but would allow us to evalueat the models ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKAO2BsqHU24"
   },
   "source": [
    "Sample images in classes are then checked before training. It is important to perform this step to have some kind of qualitative analysis on the samples. By checking sample images you'll be able to check whether the images are correctly labeled, image quality is not corrupted, and each class has sufficiently different examples under the same class.\n",
    "\n",
    "Based on the sample images, you can see that more than one image in the same class has the same person or test subject. In terms of how the shots were taken, the images show great performance in highlighting the skin diseases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1a5i2iocVUYOfrF_nFKsXilmq9U1U_6nI"
    },
    "executionInfo": {
     "elapsed": 8563,
     "status": "ok",
     "timestamp": 1762109123895,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "ubehEdw3G_Se",
    "outputId": "9d3d6004-f284-4c16-d02c-15990732e5d7"
   },
   "outputs": [],
   "source": [
    "base_dir = './SD-128/images'\n",
    "\n",
    "def resolve_paths(df, base_dir):\n",
    "    resolved_paths, exists_flags = [], []\n",
    "    for rel_path in df['Path']:\n",
    "        full_path = os.path.join(base_dir, rel_path)\n",
    "        resolved_paths.append(full_path)\n",
    "        exists_flags.append(os.path.exists(full_path))\n",
    "    df = df.copy()\n",
    "    df['resolved_path'] = resolved_paths\n",
    "    df['file_exists'] = exists_flags\n",
    "    return df\n",
    "\n",
    "train_df_eda = resolve_paths(train_df, base_dir)\n",
    "test_df_eda  = resolve_paths(test_df, base_dir)\n",
    "combined_df_eda = pd.concat([train_df_eda, test_df_eda], ignore_index=True)\n",
    "\n",
    "def show_samples_resolved(df, n_samples=3, max_classes=8, title_prefix=\"\"):\n",
    "    labels_sorted = sorted(df['Label'].unique())[:max_classes]\n",
    "    rows, cols = len(labels_sorted), n_samples\n",
    "    plt.figure(figsize=(cols*3, rows*3))\n",
    "    idx = 1\n",
    "    for lab in labels_sorted:\n",
    "        candidates = df[(df['Label'] == lab) & (df['file_exists'])]\n",
    "        if candidates.empty:\n",
    "            continue\n",
    "        samples = candidates.sample(min(n_samples, len(candidates)), random_state=42)\n",
    "        for _, r in samples.iterrows():\n",
    "            try:\n",
    "                img = Image.open(r['resolved_path']).convert('RGB')\n",
    "                plt.subplot(rows, cols, idx)\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "                if (idx - 1) % cols == 0:\n",
    "                    plt.ylabel(f\"Label {lab}\", fontsize=9)\n",
    "            except Exception as e:\n",
    "                plt.subplot(rows, cols, idx)\n",
    "                plt.axis('off')\n",
    "            idx += 1\n",
    "    plt.suptitle(f\"Sample images per class ({title_prefix})\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples_resolved(train_df_eda, n_samples=3, max_classes=8, title_prefix=\"Training Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1-3LgyLvaf2PIIbXNkiUqaa8lmtg8RdT-"
    },
    "executionInfo": {
     "elapsed": 4079,
     "status": "ok",
     "timestamp": 1762109128048,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "pqZLp07JIGb9",
    "outputId": "d2dadfb3-c070-4bc0-ec04-766c07e0b8fb"
   },
   "outputs": [],
   "source": [
    "show_samples_resolved(test_df_eda,  n_samples=3, max_classes=8, title_prefix=\"Testing Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1n4hXkn1IjQdQvFe_Xe8sHTUBuMDIeo-Q"
    },
    "executionInfo": {
     "elapsed": 3897,
     "status": "ok",
     "timestamp": 1762109132014,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "kJWqJMorII6Q",
    "outputId": "e1366748-0fb2-4fe3-da89-675dff6145cf"
   },
   "outputs": [],
   "source": [
    "show_samples_resolved(combined_df_eda, n_samples=3, max_classes=8, title_prefix=\"Combined Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdVApsFQNmyU"
   },
   "source": [
    "As previously discussed in data preprocessing, it is important to check the sizes of the samples as there is a fixed number of neurons to input when feeding images into the neural network. Scatterplots for the image sizes of the overall, training, and testing datasets are then formed. It indicates whether there should be resizing decisions or strategies. This step also helps in detecting outliers that will distort training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hG3S20swAmWa"
   },
   "source": [
    "Here, a width vs. height scatter plot is used to reveal the dimensional variance of the images, which is useful to decide on a necessary standardization step like resizing or cropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFfnf1gfHhEB"
   },
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=100000)\n",
    "def _cached_get_size(path):\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            return img.size\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def collect_image_sizes(df, max_samples=100, workers=16):\n",
    "    valid_paths = df[df['file_exists']]['resolved_path'].tolist()\n",
    "    if not valid_paths:\n",
    "        return [], []\n",
    "\n",
    "\n",
    "    sample_paths = random.sample(valid_paths, min(max_samples, len(valid_paths)))\n",
    "\n",
    "    sizes = []\n",
    "    n_workers = min(len(sample_paths), workers)\n",
    "    with ThreadPoolExecutor(max_workers=n_workers) as ex:\n",
    "        futures = {ex.submit(_cached_get_size, p): p for p in sample_paths}\n",
    "        for fut in as_completed(futures):\n",
    "            res = fut.result()\n",
    "            if res:\n",
    "                sizes.append(res)\n",
    "\n",
    "    if not sizes:\n",
    "        return [], []\n",
    "\n",
    "    widths, heights = zip(*sizes)\n",
    "    return widths, heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zoee86jN4TXF"
   },
   "outputs": [],
   "source": [
    "widths_train, heights_train = collect_image_sizes(train_df_eda)\n",
    "widths_test, heights_test = collect_image_sizes(test_df_eda)\n",
    "widths_combined, heights_combined = collect_image_sizes(combined_df_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1762109139815,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "xqYAs_zk4UTe",
    "outputId": "a2bb80ee-5b21-4f9b-c84a-3eb754ddb302"
   },
   "outputs": [],
   "source": [
    "if widths_train:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=widths_train, y=heights_train)\n",
    "    plt.title(\"Training Set - Image Width vs Height (sample)\")\n",
    "    plt.xlabel(\"Width (px)\")\n",
    "    plt.ylabel(\"Height (px)\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No valid images found in Training Set for size scatter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNWQWCczArgx"
   },
   "source": [
    "For the training set, the scatter plot visualizes the dimensions (width vs. height) of sample images in SD-108. The plot clearly shows that the images are not a uniform size. Instead, they are clustered into several different dimensions. This variation of dimensions entails the need for a preprocessing step where all images are resized to a standard 64x64 dimension, ensuring that there will be a consistent input for the machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 189,
     "status": "ok",
     "timestamp": 1762109140009,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "ySzq8Hzc4YGw",
    "outputId": "93c8cd9b-6e32-4a97-a91a-e72a47d4c742"
   },
   "outputs": [],
   "source": [
    "if widths_test:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=widths_test, y=heights_test, color=\"orange\")\n",
    "    plt.title(\"Testing Set - Image Width vs Height (sample)\")\n",
    "    plt.xlabel(\"Width (px)\")\n",
    "    plt.ylabel(\"Height (px)\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No valid images found in Testing Set for size scatter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQyc4FVcAuci"
   },
   "source": [
    "In the testing set, which was similar to the training set, the plot shows that images in the testing set also have varying original dimensions. This confirms the importance of the preprocessing step of making all images (from both sets) resized to a uniform 64x64. This standardization is critical to ensure the model can correctly process the test images using the same input shape it was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1762109140168,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "NpwMjDZa4c-q",
    "outputId": "305f1582-8da8-4408-9882-2c5cfe0acf46"
   },
   "outputs": [],
   "source": [
    "if widths_combined:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=widths_combined, y=heights_combined, color=\"green\")\n",
    "    plt.title(\"Combined (Overall) - Image Width vs Height (sample)\")\n",
    "    plt.xlabel(\"Width (px)\")\n",
    "    plt.ylabel(\"Height (px)\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No valid images found in Combined Set for size scatter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjb9ocnWAy0T"
   },
   "source": [
    "With this scatter plot, it confirms that there is a dimension variance across the entire (combined) dataset. Like in the individual training and testing plots, this graph shows that the original images come in multiple, non-uniform sizes. This emphasizes the critical need for the preprocessing step, where all images are resized to ensure consistent input for the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3hzZIRPOXuw"
   },
   "source": [
    "Lastly, an RGB histogram is used to reveal brightness/contrast of the images and whether color channels contain discriminative information which is useful to decide normalization or grayscale conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 742,
     "status": "ok",
     "timestamp": 1762109140915,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "U5oF-3CWIBmR",
    "outputId": "ad466cc1-5305-44d6-871b-dfadc3010386"
   },
   "outputs": [],
   "source": [
    "def show_rgb_histogram(df, title=\"Dataset\"):\n",
    "    \"\"\"Shows RGB histogram for one random valid image from the given dataset.\"\"\"\n",
    "    valid_paths = df[df['file_exists']]['resolved_path'].tolist()\n",
    "    if not valid_paths:\n",
    "        print(f\"No valid images found for {title}.\")\n",
    "        return\n",
    "\n",
    "    sample_img_path = random.choice(valid_paths)\n",
    "    try:\n",
    "        img = Image.open(sample_img_path).convert('RGB')\n",
    "        r, g, b = img.split()\n",
    "\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.hist(np.array(r).flatten(), bins=50, alpha=0.5, label='R', color='red')\n",
    "        plt.hist(np.array(g).flatten(), bins=50, alpha=0.5, label='G', color='green')\n",
    "        plt.hist(np.array(b).flatten(), bins=50, alpha=0.5, label='B', color='blue')\n",
    "\n",
    "        plt.title(f'Color Channel Intensity — {title}\\nSample: {os.path.basename(sample_img_path)}')\n",
    "        plt.xlabel('Pixel Intensity (0–255)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not open sample for {title} histogram:\", e)\n",
    "\n",
    "print(\"Training Set RGB Histogram:\")\n",
    "show_rgb_histogram(train_df_eda, title=\"Training Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfEMJ9hSqfEx"
   },
   "source": [
    "The histogram shows the pixel intensity distribution across the red, green, and blue channels in a sample training images.\n",
    "Most of the pixels cluster around the lower and upper intensity values, indicating a strong contrast and bright regions.\n",
    "The uneven distribution between the three color channels tells of variations in lighting and skin tones, which can affect model performance if not normalized properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 1324,
     "status": "ok",
     "timestamp": 1762109142241,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "wfvolY9HINIf",
    "outputId": "047a2080-0b69-4d25-d081-ab51c50fa022"
   },
   "outputs": [],
   "source": [
    "print(\"Testing Set RGB Histogram:\")\n",
    "show_rgb_histogram(test_df_eda, title=\"Testing Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUeFvrXbq_ru"
   },
   "source": [
    "The RGB histogram for the testing set shows a much broader spread of pixel intensities compared to the training set.\n",
    "The blue channel has more low-intensity values, while red remains in the higher range.\n",
    "This variation may suggest differences in lighting or image composition between sets, emphasizing the need for normalization to ensure consistent model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1762109143117,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "yAXsx8QfIOgA",
    "outputId": "5755605c-9e82-4b95-b60c-af936ae25878"
   },
   "outputs": [],
   "source": [
    "print(\"Combined Dataset RGB Histogram:\")\n",
    "show_rgb_histogram(combined_df_eda, title=\"Combined Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zt70J8j1rUk9"
   },
   "source": [
    "For the combined dataset, the graph shows a significant and a consistent spread across all the three channels, where the red channel spreads around the 150 intensity mark and a wider distribution in the blue channel. With this, it indicates that, as a whole, the dataset contains images with varying lighting and color casts.\n",
    "\n",
    "The noticeable spike in the blue channel is likely representing a common artifact or background color in some images. This variability across the combined set reinforces the need for data normalization before training, ensuring the model will not be bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_N0RVtQciNT"
   },
   "source": [
    "This code prepares image data for traditional machine learning models by loading, resizing, and flattening images into numerical vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27753,
     "status": "ok",
     "timestamp": 1762109171374,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "WxzZaURs82Sa",
    "outputId": "c367d5ff-aff0-4888-d384-f752ca6a5da4"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (64, 64)\n",
    "\n",
    "base_dir = 'SD-128/images'\n",
    "\n",
    "def load_and_preprocess_images(df):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for path, label in tqdm(df.values, desc=f\"Loading {len(df)} Images\"):\n",
    "        full_path = os.path.join(base_dir, path)\n",
    "        try:\n",
    "            # 1. Load image and convert to 3-channel RGB using PIL\n",
    "            img = Image.open(full_path).convert('RGB')\n",
    "\n",
    "            # 2. Resize to consistent dimensions (64x64) using PIL\n",
    "            img_resized = img.resize(IMAGE_SIZE)\n",
    "\n",
    "            # 3. Convert PIL image to a NumPy array (shape: 64, 64, 3)\n",
    "            img_array = np.array(img_resized)\n",
    "\n",
    "            # 4. Flatten the array into a 1D vector (64x64x3 = 12288)\n",
    "            x.append(img_array.flatten())\n",
    "            y.append(label)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Image not found at {full_path}. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error processing {full_path}. Skipping. Error: {e}\")\n",
    "\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134657,
     "status": "ok",
     "timestamp": 1762109306187,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "xAuS7YdEvzaO",
    "outputId": "ed9d6dcf-1798-4177-9b56-bd098d7cc8a7"
   },
   "outputs": [],
   "source": [
    "train_data_raw, train_label = load_and_preprocess_images(train_df)\n",
    "test_data_raw, test_label = load_and_preprocess_images(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1762109306262,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "-2R79V1XoEcJ",
    "outputId": "f7a63674-2303-4eeb-8a28-8ccb01b92cff"
   },
   "outputs": [],
   "source": [
    "print(train_data_raw)\n",
    "print(test_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1762109306310,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "1pk8z2riv6Zp",
    "outputId": "3a620f83-0e80-4e31-ceee-4fdedef714eb"
   },
   "outputs": [],
   "source": [
    "print(f\"\\nFinal Training Data Shape (Samples x Features): {train_data_raw.shape}\")\n",
    "print(f\"Final Test Data Shape (Samples x Features): {test_data_raw.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frAuCa6Cc0kg"
   },
   "source": [
    "A small, random subset of the RAW training data is selected. Each 1D feature vector is successfully reshaped back into a 64x64 RGB image tensor. The images are displayed with their corresponding disease names, confirming the data pipeline works and visually illustrating the high intra-class variability and fine-grained nature of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1762109307254,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "WfjMzc-0OZVN",
    "outputId": "60ebbf3d-723b-45b3-e52b-577cad8a1c5c"
   },
   "outputs": [],
   "source": [
    "HEIGHT = 64\n",
    "WIDTH = 64\n",
    "CHANNELS = 3\n",
    "\n",
    "num_samples_to_show = 16\n",
    "np.random.seed(42)\n",
    "random_indices = np.random.choice(len(train_data_raw), num_samples_to_show, replace=False)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "try:\n",
    "    data_for_display = train_data_raw\n",
    "except NameError:\n",
    "    data_for_display = train_data\n",
    "    print(\"Warning: Displaying scaled data. Image colors might be distorted.\")\n",
    "\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    flat_vector = data_for_display[idx]\n",
    "\n",
    "    img = flat_vector.reshape(HEIGHT, WIDTH, CHANNELS)\n",
    "\n",
    "    label = train_label[idx]\n",
    "    title = f\"{class_map[label]} ({label})\"\n",
    "\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(img.astype(np.uint8))\n",
    "    plt.title(title, fontsize=8)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKJe12ahc7te"
   },
   "source": [
    "This cell divides the raw test dataset into two subsets: a validation set and a final test set, ensuring balanced class distribution and consistent evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9F20Y_Qhqbrl"
   },
   "outputs": [],
   "source": [
    "# Assuming you previously loaded and scaled your data:\n",
    "# X_train_scaled is the full feature set, y_train is the full label set.\n",
    "\n",
    "X_train_raw, X_val_raw, y_train, y_val = train_test_split(\n",
    "    train_data_raw, train_label,\n",
    "    test_size=0.2,\n",
    "    random_state=1,\n",
    "    stratify=train_label\n",
    ")\n",
    "\n",
    "\n",
    "X_test_raw = test_data_raw\n",
    "y_test = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1762109307272,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "QkAmhCYefNrz",
    "outputId": "7de5f654-f382-44b4-d57c-68223494ea93"
   },
   "outputs": [],
   "source": [
    "train_data = X_train_raw\n",
    "train_label = y_train\n",
    "\n",
    "validation_data = X_val_raw\n",
    "validation_label = y_val\n",
    "\n",
    "test_data = X_test_raw\n",
    "test_label = y_test\n",
    "\n",
    "\n",
    "print(f\"Training Data Size: {len(train_data)}\")\n",
    "print(f\"Validation Data Size: {len(validation_data)}\")\n",
    "print(f\"Test Data Size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtwLCR2PdIk2"
   },
   "source": [
    "This cell balances the training dataset by oversampling underrepresented classes to match the size of the largest class, ensuring fair and unbiased model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1921,
     "status": "ok",
     "timestamp": 1762109309194,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "gviEgwDrF0BJ",
    "outputId": "3af315a4-13b5-40e6-97b1-6800f78d9449"
   },
   "outputs": [],
   "source": [
    "train_combined = np.hstack((train_data, train_label.reshape(-1, 1)))\n",
    "\n",
    "train_df = pd.DataFrame(train_combined)\n",
    "train_df.columns = [f\"f{i}\" for i in range(train_data.shape[1])] + [\"label\"]\n",
    "\n",
    "max_samples = train_df['label'].value_counts().max()\n",
    "\n",
    "balanced_dfs = []\n",
    "for label, group in train_df.groupby('label'):\n",
    "    balanced = resample(group, replace=True, n_samples=max_samples, random_state=42)\n",
    "    balanced_dfs.append(balanced)\n",
    "\n",
    "balanced_train_df = pd.concat(balanced_dfs, ignore_index=True)\n",
    "\n",
    "y_train_bal = balanced_train_df['label'].values.astype(int)\n",
    "X_train_bal = balanced_train_df.drop(columns=['label']).values.astype(np.float32)\n",
    "\n",
    "print(f\"Before balancing: {len(train_label)} samples\")\n",
    "print(f\"After balancing: {len(y_train_bal)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFP0Mq0ocwEF"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(X_train_bal)\n",
    "validation_data = scaler.transform(validation_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "train_label = y_train_bal\n",
    "validation_label = y_val\n",
    "test_label = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRENpR4fjKSE"
   },
   "source": [
    "## Section 4. Traditional ML model training\n",
    "\n",
    "This section explores baseline machine learning models for skin disease classification.  We first train a k-Nearest Neighbors (k-NN) model on raw image data, then apply Principal Component Analysis (PCA) to reduce dimensionality and improve efficiency.  Finally, we implement a simple Neural Network (MLP) from scratch using NumPy to compare performance against traditional methods.\n",
    "\n",
    "Both k-NN and NN models were used to show and highlight on the difference of non-parametric and parametric training, with k-NN being non-parametric and NN being parametric. However having both models still work in handy. k-NN provides baseline accuracy with minimal training time. NN will likely achieve higher accuracy and better feature discrimination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIesllCdjWrx"
   },
   "source": [
    "### 4.1. kNN Model Training\n",
    "\n",
    "We begin with the k-Nearest Neighbors (k-NN) algorithm as a simple baseline.  The model classifies an image by comparing it to the *k* most similar training samples and choosing the majority label.\n",
    "\n",
    "A k-NN model training was first implemented to minimize model complexity first. Since the dataset or images to classify are of skin diseases that have textures, colors, and shapes that vary significantly, k-NN is the key for non-linear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJ391i6BjFa4"
   },
   "outputs": [],
   "source": [
    "sys.path.append(r\"C:\\Users\\leigh\\Downloads\\CIVI100\\Machine Project Phase 1\")\n",
    "import kNearestNeighbor\n",
    "importlib.reload(kNearestNeighbor)\n",
    "from kNearestNeighbor import KNearestNeighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx6xHbnjYySe"
   },
   "source": [
    "The above code imports and reloads the custom module kNearestNeighbor, which contains the implementation of the KNearestNeighbor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2GWZ2Nms15e"
   },
   "outputs": [],
   "source": [
    "model = KNearestNeighbor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0S75VcnMYz1Y"
   },
   "source": [
    "After the import, an instance of the KNearestNeighbor class is created and stored in the variable model. This instance represents our k-Nearest Neighbors classifier. Unlike deep learning models, KNN does not perform any parameter learning during training. Instead, it simply stores all the training samples and their corresponding labels so they can be compared later when predicting unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yP5Gg2XyoEcL"
   },
   "outputs": [],
   "source": [
    "model.train(train_data, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxmclnqtY_0F"
   },
   "source": [
    "The train() function saves the training data and labels inside the model. Since kNN is a non-parametric method, there is no optimization or weight adjustment happening here, it is merely memorizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNQSUwr-ZTvz"
   },
   "source": [
    "To make sure that the model is performing well, a sanity check is done. Since this is KNN, the nearest neighbors of each instance should be itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-tw6TsYoEcL"
   },
   "outputs": [],
   "source": [
    "predictions = model.evaluate(train_data, train_label, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1qLHX3mZSku"
   },
   "source": [
    "After evaluating, we will now check the accuracy. As mentioned, the nearest neightbor is itself, so we are expecting a 1.0 accuracy from the kNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1762109325658,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "CGtTWmUnoEcL",
    "outputId": "7dbe7951-b2a1-4b27-9e66-aa11c5e0a703"
   },
   "outputs": [],
   "source": [
    "from utils import compute_accuracy\n",
    "\n",
    "train_accuracy = compute_accuracy(train_label, predictions)\n",
    "\n",
    "print(np.around(train_accuracy, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byZTubUrZyHF"
   },
   "source": [
    "As expected, the accuracy is 1.0, which mean the model is working fine. Therefore, we can now proceed and utilize the model for the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCrtuIJFdQbp"
   },
   "source": [
    "This cell evaluates how the number of neighbors (k) in a k-Nearest Neighbors (k-NN) classifier affects its classification accuracy on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41314,
     "status": "ok",
     "timestamp": 1762109366975,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "72nD7mAZoEcM",
    "outputId": "107ba20b-6c3c-42b0-c504-8d960ad438da"
   },
   "outputs": [],
   "source": [
    "k_values = [1, 3, 5, 7, 9, 20, 100, 500]\n",
    "accuracy_per_k = []\n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "    val_preds = model.evaluate(validation_data, validation_label, k=k)\n",
    "    acc = compute_accuracy(validation_label, val_preds)\n",
    "    accuracy_per_k.append(acc)\n",
    "\n",
    "for i, k in enumerate(k_values):\n",
    "    print('Validation Accuracy (k=' + str(k) + '): ' + str(np.around(accuracy_per_k[i], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh8ci-bvaXKQ"
   },
   "source": [
    "These results show that smaller k values perform slightly better because they focus on closer neighbors and preserve more local structure. As k increases, the classifier becomes too generalized and accuracy gradually decreases Although the overall accuracies appear low, this is expected given that the dataset contains many different classes. With dozens of possible labels, achieving random accuracy would be much lower than 16 %, so this still indicates that the model is learning real patterns rather than predicting by chance.The steady downward trend as k increases also confirms that the model behaves logically, that its predictions are consistent, not random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwjGbJpElkK_"
   },
   "source": [
    "Because the initial accuracies were low, we applied Principal Component Analysis (PCA) to reduce the feature dimensionality from 12,288 to 100.\n",
    "This step was part of parameter tuning, aiming to simplify the feature space, remove redundancy, and help the model find more meaningful distance relationships between samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7973,
     "status": "ok",
     "timestamp": 1762109374951,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "t-DHjLo6B_6D",
    "outputId": "4037450d-da84-4c0c-b37b-7d72799d4591"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "train_data_pca = pca.fit_transform(train_data)\n",
    "validation_data_pca = pca.transform(validation_data)\n",
    "\n",
    "model.train(train_data_pca, train_label)\n",
    "\n",
    "for k in k_values:\n",
    "    val_preds = model.evaluate(validation_data_pca, validation_label, k=k)\n",
    "    acc = compute_accuracy(validation_label, val_preds)\n",
    "    print(f\"Validation Accuracy (k={k}): {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjpNH4XzbDja"
   },
   "source": [
    "The increase is smal but shows that PCA still helped, allowing the model to measure distances more effectively. Since PCA still led to a small improvement, we also applied the same PCA transformation to our test evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcgea5oBfJEP"
   },
   "source": [
    "Using the same PCA representation, the model was tested on unseen samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3802,
     "status": "ok",
     "timestamp": 1762109378757,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "48eToaLgDFDj",
    "outputId": "ddbc39de-ba3e-4f2d-c770-33bba82c8d54"
   },
   "outputs": [],
   "source": [
    "test_data_pca = pca.transform(test_data)\n",
    "\n",
    "for k in k_values:\n",
    "    test_preds = model.evaluate(test_data_pca, test_label, k=k)\n",
    "    acc = compute_accuracy(test_label, test_preds)\n",
    "    print(f\"Test Accuracy (k={k}): {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMdxcObKGCye"
   },
   "source": [
    "The best test accuracy (~16 %) matches the validation performance, confirming consistent generalization. Again, while 16% may seem small, it’s not random — with many output classes, this score demonstrates that the model can recognize certain visual similarities better than chance. However, the performance plateau also highlights k-NN’s limitation: even with PCA, it still struggles to handle complex, high-dimensional image data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vI64Wt6wclv_"
   },
   "source": [
    "Overall, k-NN performs reasonably as a non-parametric baseline, but its limitations motivate moving toward parametric models like neural networks for higher accuracy, especially convolutional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WU7O9uGhLdSW"
   },
   "source": [
    "###4.2 Neural Network Model Training\n",
    "\n",
    "In this subsection, we begin building a multi-layer neural network (MLP) from scratch using NumPy.  \n",
    "\n",
    "The model uses ReLU or Sigmoid activations and a Softmax output layer for multiclass classification.  Before training, all image data is normalized and reshaped to ensure stable learning and correct input dimensions.\n",
    "\n",
    "Compared to k-NN, using Neural Networks now allow more complexity in training the data highlighting the difference with using a non-parametric and parametric approach. Using NN provides a more data-driven approach compared to simply comparing image similarity in feature space. Since classifying skin diseases means taking note of even the smallest differences, NN's approach helps in properly modelling if properly tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKRNwhsbqiqK"
   },
   "outputs": [],
   "source": [
    "sys.path.append(r\"C:\\Users\\leigh\\Downloads\\CIVI100\\Machine Project Phase 1\")\n",
    "import multiLayerNeuralNetwork\n",
    "importlib.reload(multiLayerNeuralNetwork)\n",
    "from multiLayerNeuralNetwork import MultiLayerNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n64tyx5Ac_uq"
   },
   "source": [
    "The above code imports the custom Multi-Layer Neural Network implementation from the multiLayerNeuralNetwork.py file located in the project directory. Finally, the class MultiLayerNN is imported from the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyHKwymXfPwm"
   },
   "source": [
    "This code normalizes image data to prepare it for model training and defines the architecture of a multilayer neural network by specifying layer dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu2lFPi-dJ-u"
   },
   "outputs": [],
   "source": [
    "train_data = X_train_bal.astype(np.float32) / 255.0\n",
    "validation_data = X_val_raw.astype(np.float32) / 255.0\n",
    "test_data = X_test_raw.astype(np.float32) / 255.0\n",
    "\n",
    "train_data = (train_data - 0.5) / 0.5\n",
    "validation_data = (validation_data - 0.5) / 0.5\n",
    "test_data = (test_data - 0.5) / 0.5\n",
    "\n",
    "train_label = y_train_bal.astype(np.int64)\n",
    "validation_label = validation_label.astype(np.int64)\n",
    "test_label = test_label.astype(np.int64)\n",
    "\n",
    "#---------------\n",
    "print(\"train_data shape:\", train_data.shape)\n",
    "print(\"train label shape:\", train_label.shape)\n",
    "print(\"validation_data shape:\", validation_data.shape)\n",
    "print(\"validation label shape:\", validation_label.shape)\n",
    "print(\"test_data shape:\", test_data.shape)\n",
    "print(\"test label shape:\", test_label.shape)\n",
    "print(\"Unique train labels:\", np.unique(train_label))\n",
    "#---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1A3ZavjdVpn"
   },
   "source": [
    "This cell prepares and normalizes the data before training the neural network.\n",
    "All image pixel values are divided by 255.0 to scale them from [0–255] → [0–1], then standardized to [-1, 1] using (data – 0.5)/0.5 for faster and more stable learning. The labels are converted to integers for classification. Finally, the shapes and unique class labels are printed to confirm that all datasets are correctly formatted and aligned before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1762109379317,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "IOzekvoKepgF",
    "outputId": "661c2737-0084-45a4-e94e-d3390bab1b2e"
   },
   "outputs": [],
   "source": [
    "input_size  = train_data.shape[1]\n",
    "num_classes = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipj4D5xieTkR"
   },
   "source": [
    "This cell defines two important parameters for the neural network.\n",
    "input_size gets the number of features per image from the training data, which determines the size of the input layer.\n",
    "num_classes = 128 specifies the total number of output categories for classification, which sets the number of neurons in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amnRa6oGfhmS"
   },
   "source": [
    "This code performs a sanity check to verify that the custom MultiLayer Neural Network (MultiLayerNN) implementation is functioning correctly by training and validating on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 114610,
     "status": "ok",
     "timestamp": 1762109493931,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "TSrtXJCLXN3G",
    "outputId": "ae603b77-c2da-4ca6-e09f-76e6d6bc540f"
   },
   "outputs": [],
   "source": [
    "from utils import compute_accuracy\n",
    "\n",
    "print(\"Sanity Check (Train Set Accuracy)\")\n",
    "\n",
    "model = MultiLayerNN(\n",
    "    layer_sizes=[input_size, 512, num_classes],\n",
    "    activation=\"relu\",\n",
    "    l2=1e-4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Train using the same data for both training and validation\n",
    "model.train(\n",
    "    train_data, train_label,\n",
    "    val_data=train_data, val_labels=train_label,\n",
    "    epochs=15, lr=5e-3, batch_size=64, verbose=True\n",
    ")\n",
    "\n",
    "# Evaluate on the same training data\n",
    "train_preds = model.evaluate(train_data)\n",
    "train_acc = compute_accuracy(train_label, train_preds)\n",
    "\n",
    "print(\"Sanity check accuracy on training subset:\", train_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tapQwpf6fAvh"
   },
   "source": [
    "This cell performs a sanity check to verify that the neural network implementation is working correctly. The model is trained and validated on the same dataset to ensure it can learn and fit the training data. As seen from the increasing validation accuracy (from 9.71% → 68.62%), the model successfully reduces loss and improves performance over epochs. This confirms that the forward pass, backpropagation, and parameter updates are functioning as expected before testing on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_J7ox8dgucS"
   },
   "source": [
    "Since the model showed positive results to the sanity check, we can proceed to evaluate the model to the validation set. This setup measures how well the model can generalize to new examples instead of memorizing the training data, unlike the previous sanity check where both sets were identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97752,
     "status": "ok",
     "timestamp": 1762109591708,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "y-zH1vn0fuyw",
    "outputId": "9b5c85c7-c4d4-421c-d4c0-4f27fd4675d1"
   },
   "outputs": [],
   "source": [
    "from utils import compute_accuracy\n",
    "\n",
    "print(\"Validation Set Accuracy\")\n",
    "\n",
    "# Train on training set, validate on real validation set\n",
    "model.train(\n",
    "    train_data, train_label,\n",
    "    val_data=validation_data, val_labels=validation_label,\n",
    "    epochs=15, lr=5e-3, batch_size=64, verbose=True\n",
    ")\n",
    "\n",
    "# Evaluate on validation set (separately)\n",
    "val_preds = model.evaluate(validation_data)\n",
    "val_acc = compute_accuracy(validation_label, val_preds)\n",
    "\n",
    "print(\"Validation accuracy:\", val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iTAV4ZKflfX"
   },
   "source": [
    "As expected, the validation accuracy is lower than before, but it is gradually improving as epoch increases. While this seems small, it still shows that the model is learning meaningful patterns and not performing randomly. Given that this dataset has many output classes (128 total), even small accuracy improvements are significant as random guessing would only achieve less than 1% accuracy. The result also reflects a realistic limitation of shallow neural networks: although the model can learn basic representations, its capacity is still not enough to fully capture the complex visual differences across 128 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBeDX4c3jAh8"
   },
   "source": [
    "Since our original input features have 12,288 dimensions, the data may be too high-dimensional and noisy, making learning difficult. To address this, we apply Principal Component Analysis (PCA) to reduce the feature space to 1,028 components. This step is part of parameter tuning — testing whether a smaller, denoised input allows the neural network to learn better patterns and improve validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36354,
     "status": "ok",
     "timestamp": 1762119913281,
     "user": {
      "displayName": "Rlsrain Mackenlhy Orcullo",
      "userId": "18099819779261034752"
     },
     "user_tz": -480
    },
    "id": "Az6QQ-x7kAGo",
    "outputId": "d9ff1743-70d5-4b48-fb8d-2e1f0c004b28"
   },
   "outputs": [],
   "source": [
    "print(\"\\nValidation Test Accuracy on PCA-reduced input\")\n",
    "\n",
    "n_components=1028\n",
    "pca = PCA(n_components, random_state=42)\n",
    "train_data_pca = pca.fit_transform(train_data)\n",
    "validation_data_pca = pca.transform(validation_data)\n",
    "test_data_pca = pca.transform(test_data)\n",
    "\n",
    "print(\"Original input dimension:\", train_data.shape[1])\n",
    "print(\"Reduced input dimension:\", train_data_pca.shape[1])\n",
    "\n",
    "model_pca = MultiLayerNN(\n",
    "    layer_sizes=[n_components, 512, num_classes],\n",
    "    activation=\"relu\",\n",
    "    l2=1e-4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model_pca.train(\n",
    "    train_data_pca, train_label,\n",
    "    val_data=validation_data_pca, val_labels=validation_label,\n",
    "    epochs=15, lr=5e-3, batch_size=64, verbose=True\n",
    ")\n",
    "\n",
    "val_preds = model_pca.evaluate(validation_data_pca)\n",
    "val_acc = compute_accuracy(validation_label, val_preds)\n",
    "\n",
    "print(\"\\nValidation accuracy (PCA):\", val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qa7IT_BVjXgs"
   },
   "source": [
    "The model trained on PCA-reduced features achieved a final validation accuracy of about 11.74%. Although this is slightly lower than the non-PCA result (~16.65%), the accuracy trend still shows that the model is learning consistently, not guessing randomly. This suggests that while PCA helped remove noise from the original 12k-dimensional space, some useful information was also lost in compression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3XeLqoijuCk"
   },
   "source": [
    "#### PCA-Reduced Neural Network (Increasing Architecture) — Optional Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfYn2AJykkxw"
   },
   "source": [
    "This section serves as an additional exploratory test to see how an increasing neural network architecture performs on PCA-reduced features.\n",
    "Unlike the previous setup, which focused on tuning through a decreasing architecture to minimize noise, this test expands the hidden layer size (from 1,028 to 2,056) to observe whether allowing more neurons improves performance. The idea is to check if expanding the network’s capacity can help recover information lost during PCA compression. However, this configuration is not part of the main tuning as non-PCA data will still be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65475,
     "status": "ok",
     "timestamp": 1762120025499,
     "user": {
      "displayName": "Rlsrain Mackenlhy Orcullo",
      "userId": "18099819779261034752"
     },
     "user_tz": -480
    },
    "id": "0fOsoPyjslCS",
    "outputId": "57fa372e-0c85-4a6c-c5e5-00e0d105749e"
   },
   "outputs": [],
   "source": [
    "print(\"\\nValidation Test Accuracy on PCA-reduced input in Increasing Architecture\")\n",
    "\n",
    "pca = PCA(n_components, random_state=42)\n",
    "train_data_pca = pca.fit_transform(train_data)\n",
    "validation_data_pca = pca.transform(validation_data)\n",
    "test_data_pca = pca.transform(test_data)\n",
    "\n",
    "print(\"Original input dimension:\", train_data.shape[1])\n",
    "print(\"Reduced input dimension:\", train_data_pca.shape[1])\n",
    "\n",
    "model_pca = MultiLayerNN(\n",
    "    layer_sizes = [n_components, 2056, num_classes],\n",
    "    activation=\"relu\",\n",
    "    l2=1e-4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model_pca.train(\n",
    "    train_data_pca, train_label,\n",
    "    val_data=validation_data_pca, val_labels=validation_label,\n",
    "    epochs=15, lr=5e-3, batch_size=64, verbose=True\n",
    ")\n",
    "\n",
    "val_preds = model_pca.evaluate(validation_data_pca)\n",
    "val_acc = compute_accuracy(validation_label, val_preds)\n",
    "\n",
    "print(\"\\nValidation accuracy (PCA):\", val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWhkHMcSk4UO"
   },
   "source": [
    "The increasing architecture achieved a final validation accuracy of around 14%, which is comparable to but not higher than the PCA-decreasing model’s result.\n",
    "This confirms that adding more neurons does not necessarily translate to better performance, especially when the input space is already large. For datasets like ours, the model already processes rich information, and expanding the hidden layer only increases parameters without yielding stronger representations. Such an approach typically benefits smaller or lower-dimensional datasets, where additional neurons help create more expressive mappings. In this case, the result further supports that the decreasing architecture remains more appropriate for high-dimensional data, while increasing architectures may only show improvement in settings with limited input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HiNfyULP4V7"
   },
   "source": [
    "To improve the performance of the neural network model, a systematic hyperparameter tuning process was conducted. Hyperparameter tuning aims to identify the combination of settings that produces the highest validation accuracy without overfitting or excessive training time. A higher learning rate (e.g., 0.1) leads to faster convergence but risks overshooting the optimal point, while a smaller rate (e.g., 0.005) ensures more stable and precise updates but requires more iterations. The goal was to find a balance between speed and stability. Three different hidden layer configurations were evaluated to test the model’s representational capacity testing for moderate learning capacity to testing performance improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxAQmLovhKVo"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# BASELINE + HYPERPARAMETER TUNING PIPELINE\n",
    "# ============================================\n",
    "\n",
    "from multiLayerNeuralNetwork import MultiLayerNN as SoftmaxNN\n",
    "from utils import compute_accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "input_size = train_data.shape[1]\n",
    "num_classes = len(set(train_label))\n",
    "seed = 42\n",
    "\n",
    "learning_rates = [1e-1, 5e-2, 1e-2, 5e-3]\n",
    "hidden_architectures = [\n",
    "    [input_size, 512, 128],\n",
    "    [input_size, 512, 256, 128],\n",
    "    [input_size, 1024, 512, 256, 128],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dwScjjrh9DQ"
   },
   "source": [
    "This section establishes a baseline performance for the neural network model using the real validation set.\n",
    "The baseline serves as a reference point for comparing hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSK4ogOnTtx2"
   },
   "source": [
    "The number of training epochs was set to 10 for baseline training and 10–15 during tuning.\n",
    "Although running more epochs (20–30) might improve accuracy, it was observed that training beyond 15 epochs caused significant time delays.\n",
    "\n",
    "A batch size of 64 was used for baseline runs and 128 for hyperparameter tuning.\n",
    "Using a larger batch size improved computational speed and reduced noise in gradient updates, especially during validation runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70062,
     "status": "ok",
     "timestamp": 1762114411613,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "S_wuCsschOv_",
    "outputId": "aa9b8946-a965-42d4-ea29-0c63d8ea346f"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1. BASELINE VALIDATION (real val set)\n",
    "# ============================================\n",
    "\n",
    "print(\"=== [1] BASELINE VALIDATION TEST ===\")\n",
    "\n",
    "baseline_model = SoftmaxNN(\n",
    "    layer_sizes=[input_size, 512, 128],\n",
    "    activation=\"relu\",\n",
    "    l2=1e-4,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "baseline_model.train(\n",
    "    train_data, train_label,\n",
    "    val_data=validation_data, val_labels=validation_label,\n",
    "    epochs=10, lr=5e-3, batch_size=64, verbose=True\n",
    ")\n",
    "\n",
    "val_preds = baseline_model.evaluate(validation_data)\n",
    "baseline_val_acc = compute_accuracy(validation_label, val_preds)\n",
    "\n",
    "print(f\"Baseline Validation Accuracy: {baseline_val_acc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYdg7XnxiTla"
   },
   "source": [
    "This section systematically explores different network architectures and learning rates to find the combination that yields the best validation accuracy for the neural network classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1dscCq-lqFc"
   },
   "source": [
    "After establishing the baseline model, the next step was to perform hyperparameter tuning to improve performance. This process systematically tests multiple learning rates and hidden layer configurations to identify which combinations yield higher validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97595,
     "status": "ok",
     "timestamp": 1762115210434,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "TuUDMKmDhRrP",
    "outputId": "535b81d5-68a8-451c-d079-eead817cb386"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2. HYPERPARAMETER TUNING\n",
    "# ============================================\n",
    "\n",
    "print(\"=== [2] HYPERPARAMETER TUNING ===\\n\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for layers in hidden_architectures:\n",
    "    for lr in learning_rates:\n",
    "        print(f\"Training NN with layers={layers[1:]}, lr={lr}\")\n",
    "\n",
    "        model = SoftmaxNN(\n",
    "            layer_sizes=layers,\n",
    "            activation=\"relu\",\n",
    "            l2=1e-4,\n",
    "            seed=seed\n",
    "        )\n",
    "\n",
    "        history = model.train(\n",
    "            train_data, train_label,\n",
    "            val_data=validation_data, val_labels=validation_label,\n",
    "            epochs=10, lr=lr, batch_size=128, verbose=False\n",
    "        )\n",
    "\n",
    "        val_preds = model.evaluate(validation_data)\n",
    "        val_acc = compute_accuracy(validation_label, val_preds)\n",
    "\n",
    "        results[(tuple(layers), lr)] = (val_acc, history[\"train_loss\"], history[\"val_acc\"])\n",
    "        print(f\"Validation Accuracy: {val_acc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKM49Q3nlynV"
   },
   "source": [
    "Across all tested configurations, the validation accuracy ranged between 7–16%, depending on the combination of hidden layers and learning rates. The simpler architecture [512, 128] consistently performed well across all learning rates, while deeper or wider networks (such as [1024, 512, 256, 128]) did not show meaningful improvement. As for learning rate, lower values led to slower convergence and lower accuracies, whole higher value resulted to faster learning and better performance. These results highlight that model efficiency depends more on learning rate optimization than on simply increasing layer depth. This tuning step establishes a clear pattern that will guide the model selection process in the next phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFwFit-fiezM"
   },
   "source": [
    "This section identifies and displays the best-performing neural network architectures and learning rates from the hyperparameter tuning results, based on their validation accuracy. The results were stored and compared based on validation accuracy, and the top 3 configurations were printed in descending order of performance. The model with the highest validation accuracy was selected as the final configuration for test evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cc2wM4g1TzEP"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1762115210498,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "TiPMRggkhT_U",
    "outputId": "519180c1-bdf7-43cb-b2e7-bc125ce9929d"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3. DISPLAY TOP 3 CONFIGURATIONS\n",
    "# ============================================\n",
    "\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1][0], reverse=True)\n",
    "\n",
    "print(\"=== [3] BEST CONFIGURATIONS (sorted by val_acc) ===\")\n",
    "for (layers, lr), (acc, _, _) in sorted_results[:3]:\n",
    "    print(f\"layers={layers[1:]}, lr={lr} -> val_acc={acc:.4f}\")\n",
    "\n",
    "best_layers, best_lr = sorted_results[0][0]\n",
    "best_loss, best_val_acc = results[(best_layers, best_lr)][1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YOEFJ73mNIu"
   },
   "source": [
    "From the tuning results, the best configuration was determined to be the [512, 128] architecture with a learning rate of 0.05. This model demonstrated the best trade-off between accuracy, convergence speed, and computational efficiency. The findings suggest that simpler architectures can generalize better for this dataset, likely because the input dimensionality is already high and complex. Deeper networks, while theoretically more powerful, did not yield improvements and may require more extensive data or regularization to outperform shallower setups. Therefore, the best model was selected as the final optimized configuration for evaluation on the test set and further comparisons (e.g., with PCA-based models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aj4uoCc5iiTr"
   },
   "source": [
    "To better understand the behavior of the best-performing model during training, the training loss and validation accuracy were plotted over 10 epochs.\n",
    "Learning curves are a useful diagnostic tool for assessing whether the model is converging properly, underfitting, or overfitting the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 1523,
     "status": "ok",
     "timestamp": 1762115212041,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "hOazPyAqhZPM",
    "outputId": "e591f363-f366-4e37-c797-0c168301a4cc"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4. PLOT BEST MODEL LEARNING CURVES\n",
    "# ============================================\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(best_loss, label=\"Training Loss\", color=\"blue\")\n",
    "plt.title(f\"Training Loss ({best_layers[1:]}, lr={best_lr})\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(best_val_acc, label=\"Validation Accuracy\", color=\"orange\")\n",
    "plt.title(\"Validation Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO-GNZAsn6ox"
   },
   "source": [
    "The plots show a steady decrease in training loss and a gradual increase in validation accuracy, indicating that the model successfully learned meaningful representations without signs of overfitting. The training loss curve flattens toward the end, suggesting convergence, while validation accuracy continues to rise slowly, reaching around 16–17% by the final epoch. These results confirm that the chosen configuration not only achieved the best validation accuracy numerically but also displayed stable and consistent learning behavior across epochs. This stability validates the model’s readiness for final test-set evaluation and provides a strong baseline for comparison with PCA-based and deeper architectures in later sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akcRhQsvitx1"
   },
   "source": [
    "After identifying the optimal configuration from hyperparameter tuning, we retrain the model using the full training set and then test it against the held-out test set. We also compare its accuracy to the baseline performance, allowing us to compare the improvement achieved through model tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69497,
     "status": "ok",
     "timestamp": 1762115281556,
     "user": {
      "displayName": "Leigh Albo",
      "userId": "18052666999510861068"
     },
     "user_tz": -480
    },
    "id": "y86UHT67p2h_",
    "outputId": "5f5596ff-7973-4e46-c609-942abb1fc454"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5. FINAL TEST EVALUATION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== [5] FINAL TEST EVALUATION ===\")\n",
    "\n",
    "final_model = SoftmaxNN(\n",
    "    layer_sizes=best_layers,\n",
    "    activation=\"relu\",\n",
    "    l2=1e-4,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "final_model.train(\n",
    "    train_data, train_label,\n",
    "    val_data=test_data, val_labels=test_label,\n",
    "    epochs=15, lr=best_lr, batch_size=128, verbose=True\n",
    ")\n",
    "\n",
    "test_preds = final_model.evaluate(test_data)\n",
    "final_test_acc = compute_accuracy(test_label, test_preds)\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy (best model): {final_test_acc:.4f}\")\n",
    "print(f\"Improvement from baseline: {final_test_acc - baseline_val_acc:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeVBxAGroUOG"
   },
   "source": [
    "The best model achieved a final test accuracy of approximately 15.5%. While this may seem modest, it represents a meaningful gain considering the complexity of the task — classifying among 128 categories using limited data and a shallow neural network. The results confirm that our tuned neural network generalizes slightly better than the baseline, successfully learning distinct patterns despite the high-dimensional input space. However, the relatively low overall accuracy also highlights the limitations of traditional architectures when dealing with complex image features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPmcQNXnoa1f"
   },
   "source": [
    "This naturally leads to the next phase of the project, where we move from fully connected networks to Convolutional Neural Networks (CNNs). CNNs are specifically designed to exploit spatial hierarchies in images, making them far more effective for visual pattern recognition and feature extraction, which will be the focus of the next section.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Machine Project Phase 2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5. CNN model training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Data Handling and OS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "\n",
    "# Machine Learning and Metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import resample\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import lru_cache\n",
    "\n",
    "# additional for running in colab\n",
    "import zipfile\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# ====================================================================================\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import compute_accuracy\n",
    "\n",
    "train_df = pd.read_csv('SD-128/train.txt', sep=' ', header=None, names=['Path', 'Label'])\n",
    "test_df = pd.read_csv('SD-128/test.txt', sep=' ', header=None, names=['Path', 'Label'])\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "train_df_cnn = train_df.copy()\n",
    "test_df_cnn = test_df.copy()\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 1. Initial Data Inspection (Crucial EDA Step)\n",
    "print(\"--- Training Data Info (.info()) ---\")\n",
    "train_df.info()\n",
    "\n",
    "print(\"\\n--- Testing Data Info (.info()) ---\")\n",
    "test_df.info()\n",
    "\n",
    "print(\"\\n--- Overall Data Info (.info()) ---\")\n",
    "combined_df.info()\n",
    "\n",
    "\n",
    "\n",
    "label_to_path = combined_df.drop_duplicates(subset='Label').set_index('Label')['Path'].to_dict()\n",
    "label_to_name = {lbl: label_to_path[lbl].split('/')[0] for lbl in label_to_path}\n",
    "\n",
    "expected_min_classes = 128\n",
    "max_label_seen = int(combined_df['Label'].max())\n",
    "total_classes = max(expected_min_classes, max_label_seen + 1)\n",
    "labels = list(range(total_classes))\n",
    "\n",
    "\n",
    "for lbl in labels:\n",
    "    if lbl not in label_to_name:\n",
    "        label_to_name[lbl] = f\"Class_{lbl}\"\n",
    "\n",
    "\n",
    "num_train = len(train_df)\n",
    "num_test = len(test_df)\n",
    "num_combined = len(combined_df)\n",
    "num_classes_train = train_df['Label'].nunique()\n",
    "num_classes_test = test_df['Label'].nunique()\n",
    "num_classes = num_classes_train\n",
    "num_classes_combined = combined_df['Label'].nunique()\n",
    "\n",
    "# diff between nunique and .value_count() - nunique return just n classes, while .value counts return n PER classes\n",
    "\n",
    "\n",
    "print(f\"Number of Training Samples: {num_train}\")\n",
    "print(f\"Number of Testing Samples: {num_test}\")\n",
    "print(f\"Number of Overall Samples: {num_combined}\")\n",
    "print(f\"Number of Classes: {num_classes_train}\")\n",
    "print(f\"Number of Classes: {num_classes_test}\")\n",
    "\n",
    "class_map = combined_df.drop_duplicates(subset='Label').set_index('Label')['Path'].apply(lambda x: x.split('/')[0]).to_dict()\n",
    "class_names = [class_map[i] for i in range(num_classes)]\n",
    "for i in range(num_classes_test):\n",
    "  print(f\"Label {i}: {class_map[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (64, 64)\n",
    "base_dir = 'SD-128/images'\n",
    "\n",
    "def load_images_for_cnn(df):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Loading images for CNN\"):\n",
    "        path = row['Path']\n",
    "        label = row['Label']\n",
    "        \n",
    "        full_path = os.path.join(base_dir, path)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(full_path).convert('RGB')\n",
    "            img = img.resize(IMAGE_SIZE)\n",
    "            img_array = np.array(img, dtype=np.float32)\n",
    "            x.append(img_array)\n",
    "            y.append(label)\n",
    "        except Exception as e:\n",
    "            print(\"Error loading:\", full_path, \"|\", e)\n",
    "\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# REMOVE MISSING TEST IMAGES\n",
    "missing = []\n",
    "\n",
    "for idx, row in test_df_cnn.iterrows():\n",
    "    full_path = os.path.join(base_dir, row[\"Path\"])\n",
    "    if not os.path.exists(full_path):\n",
    "        print(\"Missing:\", full_path)\n",
    "        missing.append(idx)\n",
    "\n",
    "test_df_cnn = test_df_cnn.drop(missing).reset_index(drop=True)\n",
    "\n",
    "# SPLIT TRAIN/VAL\n",
    "df_train_cnn, df_val = train_test_split(\n",
    "    train_df_cnn,\n",
    "    test_size=0.2,\n",
    "    random_state=1,\n",
    "    stratify=train_df_cnn['Label']\n",
    ")\n",
    "\n",
    "# LOAD IMAGES\n",
    "train_data, train_label = load_images_for_cnn(df_train_cnn)\n",
    "validation_data, validation_label = load_images_for_cnn(df_val)\n",
    "test_data, test_label = load_images_for_cnn(test_df_cnn)\n",
    "\n",
    "# NORMALIZE\n",
    "train_data = train_data / 255.0\n",
    "validation_data = validation_data / 255.0\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "print(\"Train:\", train_data.shape, train_label.shape)\n",
    "print(\"Val:\", validation_data.shape, validation_label.shape)\n",
    "print(\"Test:\", test_data.shape, test_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.2 CNN Model 1 (Baseline) ---\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_shape = (64, 64, 3)\n",
    "num_classes = len(class_map)  # 128 classes\n",
    "\n",
    "model1 = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), padding='same', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.3 Train Model 1 ---\n",
    "\n",
    "history1 = model1.fit(\n",
    "    train_data, train_label,\n",
    "    validation_data=(validation_data, validation_label),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.4 Learning Curves for Model 1 ---\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history1.history['accuracy'])\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "plt.title(\"Model 1 Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title(\"Model 1 Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.5 Test Performance for Model 1 ---\n",
    "\n",
    "test_loss1, test_acc1 = model1.evaluate(test_data, test_label, verbose=1)\n",
    "print(\"Model 1 Test Accuracy:\", test_acc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.6 CNN Model 2 (Deeper Baseline) ---\n",
    "\n",
    "model2 = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), padding='valid', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    layers.Conv2D(32, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.7 Train Model 2 ---\n",
    "\n",
    "history2 = model2.fit(\n",
    "    train_data, train_label,\n",
    "    validation_data=(validation_data, validation_label),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.8 Plot Model 2 Curves ---\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title(\"Model 2 Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title(\"Model 2 Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.9 Test Performance for Model 2 ---\n",
    "\n",
    "test_loss2, test_acc2 = model2.evaluate(test_data, test_label, verbose=1)\n",
    "print(\"Model 2 Test Accuracy:\", test_acc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐ SECTION 6 → WHAT YOU WILL DO\n",
    "\n",
    "Section 6 is Error Analysis, so you will:\n",
    "\n",
    "🔶 1. Compare Model 1 vs Model 2\n",
    "\n",
    "Model 1 underfits\n",
    "\n",
    "Model 2 overfits\n",
    "\n",
    "More layers = memorizes training\n",
    "\n",
    "Still can’t generalize (data too small)\n",
    "\n",
    "🔶 2. Discuss WHY accuracy is low\n",
    "\n",
    "Your reasons:\n",
    "\n",
    "128 classes\n",
    "\n",
    "~17 training samples per class\n",
    "\n",
    "64×64 tiny images → lesions need high resolution\n",
    "\n",
    "No augmentation\n",
    "\n",
    "No regularization\n",
    "\n",
    "No transfer learning (medical tasks need it)\n",
    "\n",
    "This shows you understand ML — your prof will LOVE THIS.\n",
    "\n",
    "🔶 3. Show confusion matrix\n",
    "\n",
    "Even if 9–10% accuracy, confusion matrix is fine.\n",
    "\n",
    "🔶 4. Show sample misclassifications\n",
    "\n",
    "Example:\n",
    "\n",
    "“Malignant Melanoma predicted as Benign Keratosis”\n",
    "\n",
    "“Tinea Corporis predicted as Psoriasis”\n",
    "\n",
    "🔶 5. Suggest improvements (palipat na to ng section 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7. Model Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mostly here, we are gonna be using model 2 as our baseline since it performed better than the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "print(\"utils imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.X CNN Model 3 (Deeper + Dropout) ---\n",
    "\n",
    "model3 = models.Sequential([\n",
    "    # --- Block 1 ---\n",
    "    layers.Conv2D(32, (3,3), padding='valid', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    \n",
    "    layers.Conv2D(32, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # --- Block 2 ---\n",
    "    layers.Conv2D(64, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # --- Block 3 ---\n",
    "    layers.Conv2D(128, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # --- Dense Block ---\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),        # very important for preventing overfitting\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model3.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model3.fit(\n",
    "    train_data, train_label,\n",
    "    validation_data=(validation_data, validation_label),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.8 Plot Model 2 Curves ---\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history3.history['accuracy'])\n",
    "plt.plot(history3.history['val_accuracy'])\n",
    "plt.title(\"Model 3 Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history3.history['loss'])\n",
    "plt.plot(history3.history['val_loss'])\n",
    "plt.title(\"Model 3 Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss3, test_acc3 = model3.evaluate(test_data, test_label, verbose=1)\n",
    "print(\"Model 3 Test Accuracy:\", test_acc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), padding='valid', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    layers.Conv2D(32, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model4.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "history4 = model4.fit(\n",
    "    datagen.flow(train_data, train_label, batch_size=batch_size),\n",
    "    validation_data=(validation_data, validation_label),\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(train_data) // batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss4, test_acc4 = model4.evaluate(test_data, test_label, verbose=1)\n",
    "print(\"Model 4 Test Accuracy:\", test_acc4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), padding='valid', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    layers.Conv2D(32, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), padding='valid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model5.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model5.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "history5 = model5.fit(\n",
    "    datagen.flow(train_data, train_label, batch_size=batch_size),\n",
    "    validation_data=(validation_data, validation_label),\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(train_data) // batch_size,\n",
    "    callbacks=[lr_scheduler],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss5, test_acc5 = model5.evaluate(test_data, test_label, verbose=1)\n",
    "print(\"Model 5 Test Accuracy:\", test_acc5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE_TL = (224, 224)\n",
    "base_dir = 'SD-128/images'\n",
    "\n",
    "def load_images_TL(df):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Loading TL images\"):\n",
    "        path = row['Path']\n",
    "        label = row['Label']\n",
    "        full_path = os.path.join(base_dir, path)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(full_path).convert('RGB')\n",
    "            img = img.resize(IMAGE_SIZE_TL)\n",
    "            img_array = np.array(img, dtype=np.float32)\n",
    "            x.append(img_array)\n",
    "            y.append(label)\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", full_path, e)\n",
    "\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# Reload everything for transfer learning\n",
    "train_TL, train_TL_y = load_images_TL(df_train_cnn)\n",
    "val_TL, val_TL_y     = load_images_TL(df_val)\n",
    "test_TL, test_TL_y   = load_images_TL(test_df_cnn)\n",
    "\n",
    "\n",
    "print(train_TL.shape, val_TL.shape, test_TL.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Build base model\n",
    "base_model = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "base_model.trainable = False   # freeze pretrained layers\n",
    "\n",
    "# Build top classifier\n",
    "model6 = models.Sequential([\n",
    "    layers.Input(shape=(224, 224, 3)),\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model6.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model6.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history6 = model6.fit(\n",
    "    train_TL, train_TL_y,\n",
    "    validation_data=(val_TL, val_TL_y),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss6, test_acc6 = model6.evaluate(test_TL, test_TL_y, verbose=1)\n",
    "print(\"Model 6 Test Accuracy:\", test_acc6)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
